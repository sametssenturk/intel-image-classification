{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ef3d04",
   "metadata": {},
   "source": [
    "# Intel Görüntü Sınıflandırması - CNN Derin Öğrenme Projesi\n",
    "\n",
    "## Akbank Derin Öğrenme Bootcamp Projesi\n",
    "\n",
    "Bu proje kapsamında, CNN (Convolutional Neural Network) mimarisi kullanarak Intel görüntü veri seti üzerinde 6 farklı doğa kategorisini sınıflandıran bir derin öğrenme modeli geliştirilecektir.\n",
    "\n",
    "### Veri Seti Bilgileri:\n",
    "- **Kaynak:** Intel Image Classification Dataset (Kaggle)\n",
    "- **Kategoriler:** Buildings, Forest, Glacier, Mountain, Sea, Street (6 sınıf)\n",
    "- **Boyut:** 25.000 görüntü (150x150 piksel)\n",
    "- **Dağılım:** ~14k train, ~3k test, ~7k prediction\n",
    "\n",
    "### Proje Aşamaları:\n",
    "1. Veri Önişleme ve Görselleştirme\n",
    "2. Data Augmentation\n",
    "3. Model Tasarımı ve Eğitimi\n",
    "4. Model Değerlendirmesi\n",
    "5. Grad-CAM Görselleştirme\n",
    "6. Prediction Verisi Üzerinde Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f1fa11",
   "metadata": {},
   "source": [
    "## 1. Kütüphanelerin İçe Aktarılması\n",
    "\n",
    "Projenin tüm aşamalarında kullanacağımız kütüphaneleri içe aktaralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temel veri işleme ve görselleştirme kütüphaneleri\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow ve Keras kütüphaneleri\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16  \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Sklearn kütüphaneleri\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Grad-CAM için gerekli kütüphaneler\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Rastgelelik kontrolü için seed değerleri\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Kütüphaneler başarıyla yüklendi!\")\n",
    "print(f\"TensorFlow versiyon: {tf.__version__}\")\n",
    "print(f\"GPU mevcut: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3353601",
   "metadata": {},
   "source": [
    "## 2. Veri Setinin Yüklenmesi ve Keşfi\n",
    "\n",
    "Intel görüntü veri setinin yapısını inceleyelim ve temel bilgileri elde edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011219de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri seti yollarını tanımlayalım\n",
    "base_path = '/kaggle/input/intel-image-classification'\n",
    "train_path = '/kaggle/input/intel-image-classification/seg_train/seg_train'\n",
    "test_path = '/kaggle/input/intel-image-classification/seg_test/seg_test'\n",
    "pred_path = '/kaggle/input/intel-image-classification/seg_pred/seg_pred'\n",
    "\n",
    "# Sınıf isimleri ve kodları\n",
    "class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "class_dict = {\n",
    "    'buildings': 0,\n",
    "    'forest': 1,\n",
    "    'glacier': 2,\n",
    "    'mountain': 3,\n",
    "    'sea': 4,\n",
    "    'street': 5\n",
    "}\n",
    "\n",
    "print(\"Veri Seti Yolları:\")\n",
    "print(f\"Ana yol: {base_path}\")\n",
    "print(f\"Eğitim verisi: {train_path}\")\n",
    "print(f\"Test verisi: {test_path}\")\n",
    "print(f\"Tahmin verisi: {pred_path}\")\n",
    "print(f\"\\nSınıflar: {class_names}\")\n",
    "\n",
    "# Veri seti yapısını inceleyelim\n",
    "def explore_dataset_structure(path, dataset_name):\n",
    "    \"\"\"Veri seti yapısını ve her sınıftaki görüntü sayısını inceleyen fonksiyon\"\"\"\n",
    "    print(f\"\\n{dataset_name} Veri Seti Analizi:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        folders = os.listdir(path)\n",
    "        total_images = 0\n",
    "        \n",
    "        for folder in sorted(folders):\n",
    "            folder_path = os.path.join(path, folder)\n",
    "            if os.path.isdir(folder_path):\n",
    "                image_count = len(os.listdir(folder_path))\n",
    "                total_images += image_count\n",
    "                print(f\"{folder}: {image_count} görüntü\")\n",
    "        \n",
    "        print(f\"Toplam: {total_images} görüntü\")\n",
    "        return total_images\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Hata: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Her veri setini inceleyelim\n",
    "train_count = explore_dataset_structure(train_path, \"EĞİTİM\")\n",
    "test_count = explore_dataset_structure(test_path, \"TEST\")\n",
    "\n",
    "# Prediction klasörü farklı yapıda olduğu için ayrı inceleyeceğiz\n",
    "print(f\"\\nTAHMİN Veri Seti Analizi:\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    pred_images = os.listdir(pred_path)\n",
    "    pred_count = len([f for f in pred_images if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"Toplam tahmin görüntüsü: {pred_count}\")\n",
    "except Exception as e:\n",
    "    print(f\"Hata: {e}\")\n",
    "    pred_count = 0\n",
    "\n",
    "print(f\"\\nGENEL ÖZET:\")\n",
    "print(f\"Toplam eğitim görüntüsü: {train_count}\")\n",
    "print(f\"Toplam test görüntüsü: {test_count}\")\n",
    "print(f\"Toplam tahmin görüntüsü: {pred_count}\")\n",
    "print(f\"Genel toplam: {train_count + test_count + pred_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a49f2",
   "metadata": {},
   "source": [
    "## 3. Veri Görselleştirme ve İstatistiksel Analiz\n",
    "\n",
    "Her kategoriden örnek görüntüleri görselleştirelim ve veri setinin dağılımını analiz edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04daf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her sınıftan örnek görüntüleri görselleştiren fonksiyon\n",
    "def visualize_sample_images(path, class_names, num_samples=3):\n",
    "    \"\"\"Her sınıftan örnek görüntüleri gösteren fonksiyon\"\"\"\n",
    "    fig, axes = plt.subplots(len(class_names), num_samples, figsize=(15, 20))\n",
    "    fig.suptitle('Her Sınıftan Örnek Görüntüler', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        \n",
    "        try:\n",
    "            # Sınıf klasöründeki görüntüleri listele\n",
    "            images = os.listdir(class_path)\n",
    "            images = [img for img in images if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            # Rastgele örnek seç\n",
    "            sample_images = np.random.choice(images, min(num_samples, len(images)), replace=False)\n",
    "            \n",
    "            for j, img_name in enumerate(sample_images):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                \n",
    "                # Görüntüyü yükle ve göster\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].set_title(f'{class_name.title()}', fontweight='bold')\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Hata ({class_name}): {e}\")\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Örnek görüntüleri göster\n",
    "visualize_sample_images(train_path, class_names, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf dağılımlarını görselleştiren fonksiyon\n",
    "def plot_class_distribution(path, title, class_names):\n",
    "    \"\"\"Sınıf dağılımını görselleştiren fonksiyon\"\"\"\n",
    "    class_counts = []\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        try:\n",
    "            count = len(os.listdir(class_path))\n",
    "            class_counts.append(count)\n",
    "        except:\n",
    "            class_counts.append(0)\n",
    "    \n",
    "    # Bar grafiği\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(class_names, class_counts, color=plt.cm.viridis(np.linspace(0, 1, len(class_names))))\n",
    "    plt.title(f'{title} - Sınıf Dağılımı', fontweight='bold')\n",
    "    plt.xlabel('Sınıflar')\n",
    "    plt.ylabel('Görüntü Sayısı')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Her bar'ın üzerine değer yazdır\n",
    "    for bar, count in zip(bars, class_counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 50,\n",
    "                f'{count}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Pasta grafiği\n",
    "    plt.subplot(1, 2, 2)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(class_names)))\n",
    "    plt.pie(class_counts, labels=class_names, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    plt.title(f'{title} - Yüzdelik Dağılım', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Train ve test setlerinin dağılımını görselleştir\n",
    "print(\"EĞİTİM VERİSİ DAĞILIMI:\")\n",
    "train_counts = plot_class_distribution(train_path, \"Eğitim Verisi\", class_names)\n",
    "\n",
    "print(\"\\nTEST VERİSİ DAĞILIMI:\")\n",
    "test_counts = plot_class_distribution(test_path, \"Test Verisi\", class_names)\n",
    "\n",
    "# İstatistiksel bilgileri göster\n",
    "print(\"\\nİSTATİSTİKSEL ÖZET:\")\n",
    "print(\"-\" * 50)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    train_count = train_counts[i]  \n",
    "    test_count = test_counts[i]\n",
    "    total = train_count + test_count\n",
    "    train_ratio = (train_count / total) * 100 if total > 0 else 0\n",
    "    test_ratio = (test_count / total) * 100 if total > 0 else 0\n",
    "    \n",
    "    print(f\"{class_name.upper()}:\")\n",
    "    print(f\"  Eğitim: {train_count} (%{train_ratio:.1f})\")\n",
    "    print(f\"  Test: {test_count} (%{test_ratio:.1f})\")\n",
    "    print(f\"  Toplam: {total}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf0c1a",
   "metadata": {},
   "source": [
    "## 4. Veri Önişleme ve Etiketleme\n",
    "\n",
    "Görüntüleri model için uygun formata dönüştürelim ve etiketleri sayısal değerlere çevirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntü boyutları ve parametreler\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_path, class_names, limit_per_class=None):\n",
    "    \"\"\"\n",
    "    Veri setini yükleyen ve önişleyen fonksiyon\n",
    "    \n",
    "    Args:\n",
    "        data_path: Veri seti klasör yolu\n",
    "        class_names: Sınıf isimleri listesi\n",
    "        limit_per_class: Her sınıftan alınacak maksimum görüntü sayısı (None = tümü)\n",
    "    \n",
    "    Returns:\n",
    "        images: Numpy array olarak görüntüler\n",
    "        labels: Numpy array olarak etiketler\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Veri yükleniyor: {data_path}\")\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        print(f\"  {class_name} sınıfı yükleniyor...\")\n",
    "        \n",
    "        try:\n",
    "            # Sınıf klasöründeki tüm görüntüleri listele\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            # Eğer limit varsa, rastgele örnekle\n",
    "            if limit_per_class and len(image_files) > limit_per_class:\n",
    "                image_files = np.random.choice(image_files, limit_per_class, replace=False)\n",
    "            \n",
    "            class_images = []\n",
    "            class_labels = []\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                \n",
    "                # Görüntüyü yükle\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    # BGR'dan RGB'ye dönüştür\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Boyutlandır\n",
    "                    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                    \n",
    "                    # Normalize etme - ImageDataGenerator'da yapılacak\n",
    "                    img = img.astype('float32')  # 0-255 aralığında bırak\n",
    "                    \n",
    "                    class_images.append(img)\n",
    "                    class_labels.append(class_idx)\n",
    "            \n",
    "            images.extend(class_images)\n",
    "            labels.extend(class_labels)\n",
    "            \n",
    "            print(f\"    {len(class_images)} görüntü yüklendi\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Hata: {e}\")\n",
    "    \n",
    "    print(f\"Toplam {len(images)} görüntü yüklendi\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Eğitim verisini yükle\n",
    "print(\"EĞİTİM VERİSİ YÜKLENİYOR...\")\n",
    "X_train_full, y_train_full = load_and_preprocess_data(train_path, class_names)\n",
    "\n",
    "# Test verisini yükle\n",
    "print(\"\\nTEST VERİSİ YÜKLENİYOR...\")\n",
    "X_test, y_test = load_and_preprocess_data(test_path, class_names)\n",
    "\n",
    "print(f\"\\nVERİ ÖNİŞLEME TAMAMLANDI!\")\n",
    "print(f\"Eğitim verisi şekli: {X_train_full.shape}\")\n",
    "print(f\"Eğitim etiketleri şekli: {y_train_full.shape}\")\n",
    "print(f\"Test verisi şekli: {X_test.shape}\")\n",
    "print(f\"Test etiketleri şekli: {y_test.shape}\")\n",
    "\n",
    "# Etiketleri kategorik formata dönüştür\n",
    "y_train_full_categorical = to_categorical(y_train_full, num_classes=len(class_names))\n",
    "y_test_categorical = to_categorical(y_test, num_classes=len(class_names))\n",
    "\n",
    "print(f\"Kategorik etiket şekli: {y_train_full_categorical.shape}\")\n",
    "\n",
    "# Bazı istatistikleri göster\n",
    "print(f\"\\nVERİ İSTATİSTİKLERİ:\")\n",
    "print(f\"Görüntü boyutu: {IMG_HEIGHT}x{IMG_WIDTH}x{IMG_CHANNELS}\")\n",
    "print(f\"Piksel değeri aralığı: {X_train_full.min():.3f} - {X_train_full.max():.3f}\")\n",
    "print(f\"Sınıf sayısı: {len(class_names)}\")\n",
    "print(f\"Sınıf dağılımı (eğitim): {np.bincount(y_train_full)}\")\n",
    "print(f\"Sınıf dağılımı (test): {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa90283",
   "metadata": {},
   "source": [
    "## 5. Veri Artırma (Data Augmentation)\n",
    "\n",
    "Model performansını artırmak için veri artırma tekniklerini uygulayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b14c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri artırma (Data Augmentation) ayarları - VGG16 eğitimi ve örnek görselleştirme\n",
    "\n",
    "# Genel augmentation (0-1 normalize + çeşitli dönüşümler)\n",
    "augmentation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.1,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# Validation için yalnızca normalize (örnek amaçlı)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# VGG16 için (girdi 0-255 -> Lambda içinde preprocess_input uygulanacak) ayrı jeneratörler\n",
    "vgg_train_datagen = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.1,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "vgg_val_datagen = ImageDataGenerator()\n",
    "\n",
    "\n",
    "def show_augmentation_examples():\n",
    "    \"\"\"Augmentation örneklerini gösterir (girdi: orijinal 0-255 RGB, ekranda normalize edilmiş versiyonlar).\"\"\"\n",
    "    random_idx = np.random.randint(0, len(X_train_full))\n",
    "    sample_img = X_train_full[random_idx]\n",
    "    sample_label = y_train_full[random_idx]\n",
    "    class_name = class_names[sample_label]\n",
    "\n",
    "    # Orijinal görüntü (0-255 formatı)\n",
    "    if sample_img.max() <= 1.0:\n",
    "        display_img = (sample_img * 255).astype(np.uint8)\n",
    "    else:\n",
    "        display_img = sample_img.astype(np.uint8)\n",
    "\n",
    "    img_for_aug = display_img.copy()\n",
    "    img_array = np.expand_dims(img_for_aug, axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "    axes[0].imshow(display_img)\n",
    "    axes[0].set_title(f'Orijinal\\n{class_name}', fontweight='bold', fontsize=10)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for i in range(5):\n",
    "        aug_iter = augmentation_datagen.flow(img_array, batch_size=1, shuffle=False)\n",
    "        aug_img = next(aug_iter)[0]  # 0-1 aralığında\n",
    "        aug_img = np.clip(aug_img, 0, 1)\n",
    "        axes[i+1].imshow(aug_img)\n",
    "        axes[i+1].set_title(f'Aug {i+1}', fontweight='bold', fontsize=10)\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"VERİ ARTIRMA ÖRNEKLERİ (VGG16 için de uygulanabilir genel pipeline):\\n\")\n",
    "for example_num in range(3):\n",
    "    print(f\"Örnek {example_num + 1}:\")\n",
    "    show_augmentation_examples()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be874f7a",
   "metadata": {},
   "source": [
    "## 6. Train-Validation-Test Ayrımı\n",
    "\n",
    "Eğitim verisini train ve validation setlerine ayıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0287695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim verisini train ve validation setlerine ayır (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full_categorical, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_train_full  # Her sınıftan eşit oranda örnekleme\n",
    ")\n",
    "\n",
    "print(\"VERİ SETİ AYIRIMI TAMAMLANDI!\")\n",
    "print(f\"Eğitim seti: {X_train.shape[0]} görüntü\")\n",
    "print(f\"Validation seti: {X_val.shape[0]} görüntü\")\n",
    "print(f\"Test seti: {X_test.shape[0]} görüntü\")\n",
    "\n",
    "# Sınıf dağılımlarını kontrol et\n",
    "print(f\"\\nSINIF DAĞILIMLARI:\")\n",
    "print(\"Train seti:\")\n",
    "train_class_counts = np.sum(y_train, axis=0)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}: {int(train_class_counts[i])}\")\n",
    "\n",
    "print(\"Validation seti:\")\n",
    "val_class_counts = np.sum(y_val, axis=0)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}: {int(val_class_counts[i])}\")\n",
    "\n",
    "print(\"Test seti:\")\n",
    "test_class_counts = np.sum(y_test_categorical, axis=0)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}: {int(test_class_counts[i])}\")\n",
    "\n",
    "# Sınıf ağırlıklarını hesapla (dengesiz veri seti için)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_full),\n",
    "    y=y_train_full\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(zip(np.unique(y_train_full), class_weights))\n",
    "print(f\"\\nSINIF AĞIRLIKLARI:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}: {class_weight_dict[i]:.3f}\")\n",
    "\n",
    "# Veri boyutlarını görselleştir\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Bar grafiği\n",
    "plt.subplot(1, 2, 1)\n",
    "datasets = ['Train', 'Validation', 'Test']\n",
    "sizes = [X_train.shape[0], X_val.shape[0], X_test.shape[0]]\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "bars = plt.bar(datasets, sizes, color=colors)\n",
    "plt.title('Veri Seti Boyutları', fontweight='bold')\n",
    "plt.ylabel('Görüntü Sayısı')\n",
    "\n",
    "# Bar'ların üzerine değer yazdır\n",
    "for bar, size in zip(bars, sizes):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 100,\n",
    "             f'{size}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pasta grafiği\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(sizes, labels=datasets, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "plt.title('Veri Seti Dağılımı', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51188cc9",
   "metadata": {},
   "source": [
    "## 7. Transfer Learning Modeli (VGG16)\n",
    "\n",
    "Pre-trained VGG16 modeli kullanarak transfer learning yaklaşımını uygulayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e14c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli temel parametreler\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "num_classes = len(class_names)\n",
    "BATCH_SIZE = 64  # İstersen değiştirilebilir\n",
    "\n",
    "\n",
    "def create_transfer_learning_model_vgg16(input_shape, num_classes):\n",
    "    # VGG16 tabanını yükle (top katmanlar hariç)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # İlk aşama: feature extractor\n",
    "    model = Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Lambda(lambda x: tf.keras.applications.vgg16.preprocess_input(x * 255.0), name='vgg16_preprocess'),\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "print(\"TRANSFER LEARNING MODELİ OLUŞTURULUYOR (VGG16)...\")\n",
    "vgg_transfer_model = create_transfer_learning_model_vgg16(input_shape, num_classes)\n",
    "vgg_transfer_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"\\nVGG16 TRANSFER MODEL ÖZETİ:\")\n",
    "vgg_transfer_model.summary()\n",
    "\n",
    "vgg_transfer_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
    "    ModelCheckpoint('vgg16_transfer_best.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    " ]\n",
    "\n",
    "# VGG16 için generatorlar (X_train şu anda 0-1 aralığında; Lambda içinde *255 yapılıyor)\n",
    "vgg_train_generator = vgg_train_datagen.flow(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "vgg_val_generator = vgg_val_datagen.flow(\n",
    "    X_val, y_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "import math\n",
    "print(\"\\nVGG16 TRANSFER LEARNING MODELİ EĞİTİLİYOR...\")\n",
    "vgg_transfer_history = vgg_transfer_model.fit(\n",
    "    vgg_train_generator,\n",
    "    steps_per_epoch=math.ceil(len(X_train) / BATCH_SIZE),\n",
    "    epochs=50,\n",
    "    validation_data=vgg_val_generator,\n",
    "    validation_steps=math.ceil(len(X_val) / BATCH_SIZE),\n",
    "    callbacks=vgg_transfer_callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nVGG16 TRANSFER LEARNING EĞİTİMİ TAMAMLANDI!\")\n",
    "vgg_transfer_final_val_accuracy = max(vgg_transfer_history.history['val_accuracy'])\n",
    "vgg_transfer_best_epoch = vgg_transfer_history.history['val_accuracy'].index(vgg_transfer_final_val_accuracy) + 1\n",
    "print(f\"VGG16 - En iyi validation accuracy: {vgg_transfer_final_val_accuracy:.4f} (Epoch {vgg_transfer_best_epoch})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ea2dc",
   "metadata": {},
   "source": [
    "## 8. Model Performans Değerlendirmesi\n",
    "\n",
    "Eğitim sürecini analiz edelim ve accuracy/loss grafiklerini çizdirelim (VGG16 Transfer Modeli)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history_simple(history, title=\"VGG16 Transfer Model Eğitim Süreci\"):\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.title(f'{title} - Accuracy', fontweight='bold')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title(f'{title} - Loss', fontweight='bold')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "print(\"VGG16 TRANSFER EĞİTİM SÜRECİ:\")\n",
    "plot_training_history_simple(vgg_transfer_history, \"VGG16 Transfer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9956ae1c",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix ve Classification Report\n",
    "\n",
    "Test verisi üzerinde VGG16 transfer modelinin performansını analiz edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST VERİSİ ÜZERİNDE DEĞERLENDİRME (VGG16 TEK MODEL)\n",
    "print(\"TEST VERİSİ ÜZERİNDE TAHMİNLER YAPILIYOR (VGG16)...\")\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
    "    axes[0].set_title(f'{title} (Ham)', fontweight='bold')\n",
    "    axes[0].set_xlabel('Tahmin'); axes[0].set_ylabel('Gerçek')\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
    "    axes[1].set_title(f'{title} (Normalize)', fontweight='bold')\n",
    "    axes[1].set_xlabel('Tahmin'); axes[1].set_ylabel('Gerçek')\n",
    "    plt.tight_layout(); plt.show()\n",
    "    return cm, cm_normalized\n",
    "\n",
    "# VGG16 tahminleri\n",
    "preds = vgg_transfer_model.predict(X_test, verbose=0)\n",
    "pred_classes = np.argmax(preds, axis=1)\n",
    "true_classes = np.argmax(y_test_categorical, axis=1)\n",
    "accuracy = np.mean(pred_classes == true_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "cm, cm_norm = plot_confusion_matrix(true_classes, pred_classes, class_names, \"VGG16 Transfer\")\n",
    "print(\"\\nVGG16 CLASSIFICATION REPORT:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(true_classes, pred_classes, target_names=class_names, digits=4))\n",
    "all_results['VGG16 Transfer'] = {\n",
    "    'pred_classes': pred_classes,\n",
    "    'true_classes': true_classes,\n",
    "    'accuracy': accuracy,\n",
    "    'cm': cm,\n",
    "    'cm_norm': cm_norm\n",
    "}\n",
    "\n",
    "# F1-score hesaplama\n",
    "print(\"\\n=== SINIF BAZLI F1-SKORLARI (VGG16) ===\")\n",
    "cm_vgg = all_results['VGG16 Transfer']['cm']\n",
    "f1_scores = []\n",
    "for i in range(len(class_names)):\n",
    "    tp = cm_vgg[i, i]; fp = cm_vgg[:, i].sum() - tp; fn = cm_vgg[i, :].sum() - tp\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(class_names, f1_scores, color='teal')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('VGG16 Transfer - Sınıf Bazlı F1-Score', fontweight='bold')\n",
    "for i, score in enumerate(f1_scores):\n",
    "    plt.text(i, score + 0.01, f\"{score:.2f}\", ha='center', fontweight='bold')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Sanity check evaluate()\n",
    "eval_loss, eval_acc = vgg_transfer_model.evaluate(X_test, y_test_categorical, verbose=0)\n",
    "print(\"\\n=== TEST ACCURACY SANITY CHECK ===\")\n",
    "print(f\"evaluate() acc={eval_acc:.4f} | hesaplanan acc={accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18e4ca",
   "metadata": {},
   "source": [
    "## 10. VGG16 Modeli İçin Grad-CAM Görselleştirme\n",
    "\n",
    "Transfer learning ile eğittiğimiz VGG16 modelinin test görüntülerinde hangi bölgelere odaklanarak karar verdiğini inceleyelim (Grad-CAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Adım: VGG16 Transfer Modeli İçin Grad-CAM Görselleştirme\n",
    "\n",
    "\n",
    "# --- Güvenlik Kontrolü ---\n",
    "required_symbols = ['vgg_transfer_model', 'X_test', 'y_test_categorical', 'class_names']\n",
    "for sym in required_symbols:\n",
    "    if sym not in globals():\n",
    "        raise RuntimeError(f\"Gerekli değişken bulunamadı: {sym}. Lütfen önce ilgili eğitim ve veri hücrelerini çalıştırın.\")\n",
    "\n",
    "# --- 1) Sequential modelden preprocess + base_model (VGG16) + head ayrıştırma ---\n",
    "preprocess_layer = vgg_transfer_model.get_layer('vgg16_preprocess')\n",
    "base_model = vgg_transfer_model.get_layer('vgg16')  # Orijinal VGG16 Functional\n",
    "\n",
    "# Head katmanları (base_model sonrası)\n",
    "head_layers = []\n",
    "collect = False\n",
    "for layer in vgg_transfer_model.layers:\n",
    "    if layer.name == base_model.name:\n",
    "        collect = True\n",
    "        continue\n",
    "    if collect:\n",
    "        head_layers.append(layer)\n",
    "\n",
    "# Hedef konvolüsyon katmanı\n",
    "try:\n",
    "    target_conv_layer = base_model.get_layer('block5_conv3')\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"block5_conv3 katmanı alınamadı: {e}\")\n",
    "\n",
    "# Base modelden hem hedef konv çıkışı hem de base çıkışını dönen alt model\n",
    "base_feature_model = Model(\n",
    "    inputs=base_model.input,\n",
    "    outputs=[target_conv_layer.output, base_model.output],\n",
    "    name='base_feature_model_for_gradcam'\n",
    ")\n",
    "\n",
    "# --- 2) Aktivasyon modeli (preprocess + base + head) ---\n",
    "cam_input = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), name='gradcam_input_rgb')\n",
    "preprocessed = preprocess_layer(cam_input)\n",
    "conv_acts, base_out = base_feature_model(preprocessed)\n",
    "\n",
    "x_head = base_out\n",
    "for hl in head_layers:\n",
    "    if hl.__class__.__name__ == 'InputLayer':\n",
    "        continue\n",
    "    x_head = hl(x_head)\n",
    "softmax_output = x_head\n",
    "activation_model = Model(inputs=cam_input, outputs=[conv_acts, softmax_output], name='activation_model_gradcam')\n",
    "print(\"Grad-CAM için activation model hazır:\")\n",
    "print(\" - Conv aktivasyon shape:\", activation_model.output[0].shape)\n",
    "print(\" - Softmax shape:\", activation_model.output[1].shape)\n",
    "\n",
    "# --- 3) Grad-CAM Hesaplayıcı ---\n",
    "\n",
    "def generate_grad_cam(img_array, class_index=None, eps=1e-8):\n",
    "    \"\"\"\n",
    "    img_array: (H,W,3) veya (1,H,W,3) RGB (0-255 range)\n",
    "    class_index: None -> modelin tahmin ettiği sınıf\n",
    "    Dönüş: heatmap(0-1), pred_vector\n",
    "    \"\"\"\n",
    "    if img_array.ndim == 3:\n",
    "        input_tensor = np.expand_dims(img_array, axis=0).astype('float32')\n",
    "    else:\n",
    "        input_tensor = img_array.astype('float32')\n",
    "\n",
    "    input_tf = tf.convert_to_tensor(input_tensor)\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, preds = activation_model(input_tf, training=False)\n",
    "        if class_index is None:\n",
    "            class_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, class_index]\n",
    "    grads = tape.gradient(class_channel, conv_out)  # (1,h,w,c)\n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))  # (c,)\n",
    "    conv_out = conv_out[0]  # (h,w,c)\n",
    "\n",
    "    heatmap = tf.reduce_sum(conv_out * pooled_grads, axis=-1)\n",
    "    heatmap = tf.nn.relu(heatmap).numpy()\n",
    "\n",
    "    if np.all(heatmap == 0):\n",
    "        heatmap = heatmap + eps\n",
    "\n",
    "    heatmap -= heatmap.min()\n",
    "    max_val = heatmap.max()\n",
    "    if max_val > 0:\n",
    "        heatmap /= max_val\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (img_array.shape[1], img_array.shape[0]))\n",
    "    return heatmap, preds.numpy()[0]\n",
    "\n",
    "# --- 4) Isı haritasını bindirme ---\n",
    "\n",
    "def overlay_heatmap(img, heatmap, alpha=0.45, colormap=cv2.COLORMAP_JET):\n",
    "    base = img.astype('float32')\n",
    "    if base.max() > 1.0:\n",
    "        base = base / 255.0\n",
    "    heat_uint8 = np.uint8(255 * heatmap)\n",
    "    color = cv2.applyColorMap(heat_uint8, colormap)\n",
    "    color = cv2.cvtColor(color, cv2.COLOR_BGR2RGB).astype('float32') / 255.0\n",
    "    overlay = alpha * color + (1 - alpha) * base\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    return overlay\n",
    "\n",
    "# --- 5) Her sınıftan bir test örneği seç ---\n",
    "y_true_test = np.argmax(y_test_categorical, axis=1)\n",
    "indices_per_class = {}\n",
    "for idx, cls in enumerate(y_true_test):\n",
    "    if cls not in indices_per_class:\n",
    "        indices_per_class[cls] = idx\n",
    "    if len(indices_per_class) == len(class_names):\n",
    "        break\n",
    "selected_indices = list(indices_per_class.values())\n",
    "print(f\"Her sınıftan seçilen test indeksleri: {selected_indices}\")\n",
    "\n",
    "# --- 6) Parametreler ---\n",
    "USE_TRUE_CLASS_FOR_GRADCAM = False  # True -> Grad-CAM gerçek sınıf için hesaplanır\n",
    "\n",
    "# --- 7) Görselleştirme ---\n",
    "num_samples = len(selected_indices)\n",
    "plt.figure(figsize=(4 * num_samples, 5))\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    img = X_test[idx]\n",
    "    true_cls = y_true_test[idx]\n",
    "\n",
    "    heat_grad, pred_vec = generate_grad_cam(img, class_index=true_cls if USE_TRUE_CLASS_FOR_GRADCAM else None)\n",
    "    pred_class = np.argmax(pred_vec)\n",
    "    pred_prob = pred_vec[pred_class]\n",
    "    grad_overlay = overlay_heatmap(img, heat_grad)\n",
    "\n",
    "    # Orijinal\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    title_lines = [f\"Gerçek: {class_names[true_cls]}\", f\"Tahmin: {class_names[pred_class]} ({pred_prob:.2f})\"]\n",
    "    if USE_TRUE_CLASS_FOR_GRADCAM and pred_class != true_cls:\n",
    "        title_lines.append(\"(GC hedef=gerçek)\")\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.title(\"\\n\".join(title_lines), fontsize=10, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Grad-CAM Overlay\n",
    "    plt.subplot(2, num_samples, num_samples + i + 1)\n",
    "    plt.imshow(grad_overlay)\n",
    "    plt.title('Grad-CAM', fontsize=10, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('VGG16 Transfer Modeli - Grad-CAM Odak Alanları', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "plt.show()\n",
    "\n",
    "print('Grad-CAM görselleştirme tamamlandı.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9188dd",
   "metadata": {},
   "source": [
    "## 11. Prediction Verisi Üzerinde Test (VGG16)\n",
    "\n",
    "`seg_pred` klasöründeki bağımsız prediction görüntüleri üzerinde VGG16 modelinin tahminlerini inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction verisi üzerinde VGG16 tahminleri\n",
    "\n",
    "\n",
    "prediction_path = pred_path  # Önceden tanımlandı: /kaggle/input/intel-image-classification/seg_pred/seg_pred\n",
    "print(f\"Prediction klasörü: {prediction_path}\")\n",
    "\n",
    "# Prediction klasöründeki görüntü dosyalarını listele\n",
    "all_pred_files = [f for f in os.listdir(prediction_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "print(f\"Toplam prediction görüntüsü: {len(all_pred_files)}\")\n",
    "\n",
    "# Çok fazla görsel varsa görselleştirme için ilk N tanesini seçebilirsiniz\n",
    "VISUALIZE_COUNT = 18  # 3x6 grid\n",
    "selected_files = all_pred_files[:VISUALIZE_COUNT]\n",
    "\n",
    "results = []\n",
    "\n",
    "def infer_possible_true_label(filename, class_names):\n",
    "    name_lower = filename.lower()\n",
    "    for cls in class_names:\n",
    "        if cls in name_lower:\n",
    "            return cls\n",
    "    return None\n",
    "\n",
    "images = []\n",
    "for fname in selected_files:\n",
    "    img_path = os.path.join(prediction_path, fname)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_rgb = cv2.resize(img_rgb, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    images.append((fname, img_rgb))\n",
    "\n",
    "# Batch halinde tahmin yapmak için array'e çevir (0-255 float -> Lambda preprocess işleyecek)\n",
    "if images:\n",
    "    batch_array = np.stack([img for (_, img) in images]).astype('float32')\n",
    "    preds = vgg_transfer_model.predict(batch_array, verbose=0)\n",
    "else:\n",
    "    preds = []\n",
    "\n",
    "for i, (fname, img_rgb) in enumerate(images):\n",
    "    pred_vector = preds[i]\n",
    "    predicted_class = class_names[np.argmax(pred_vector)]\n",
    "    predicted_prob = np.max(pred_vector)\n",
    "    possible_true = infer_possible_true_label(fname, class_names)\n",
    "\n",
    "    results.append({\n",
    "        'filename': fname,\n",
    "        'predicted_class': predicted_class,\n",
    "        'predicted_prob': predicted_prob,\n",
    "        'possible_true_from_name': possible_true\n",
    "    })\n",
    "\n",
    "# Görselleştirme\n",
    "cols = 6\n",
    "rows = int(np.ceil(len(images) / cols))\n",
    "plt.figure(figsize=(3*cols, 3*rows))\n",
    "for idx, (fname, img_rgb) in enumerate(images):\n",
    "    pred_class = results[idx]['predicted_class']\n",
    "    pred_prob = results[idx]['predicted_prob']\n",
    "    possible_true = results[idx]['possible_true_from_name']\n",
    "    title = f\"Tahmin: {pred_class}\\nP={pred_prob:.2f}\"\n",
    "    if possible_true is not None and possible_true != pred_class:\n",
    "        title += f\"\\n(Muht. Gerçek: {possible_true})\"\n",
    "    elif possible_true is not None and possible_true == pred_class:\n",
    "        title += f\"\\n(İsim Eşleşti)\"\n",
    "\n",
    "    plt.subplot(rows, cols, idx + 1)\n",
    "    plt.imshow(img_rgb.astype('uint8'))\n",
    "    plt.title(title, fontsize=9, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('VGG16 Transfer Modeli - Prediction Görselleri Tahminleri', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "plt.show()\n",
    "\n",
    "# Sonuçları DataFrame olarak özetle\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Prediction değerlendirmesi tamamlandı.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
